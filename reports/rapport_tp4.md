# Rapport TP4

## Exercice 1 :  Mise en route + rappel de contexte (sanity checks + o√π on en est dans la pipeline)

Pour commencer ce TP, nous r√©installons la stack Docker Compose et v√©rifions que tout est bien lanc√© :

![docker_compose](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20103450.png)

L'objectif de ce TP √©tant d'int√©grer dans notre pipeline, l'entrainement du mod√®le, le suivi de l'execution du versionning et la mise en production de ce mod√®le, nous ajoutons un service MLflow dans notre `docker-compose.yml`. Puis nous red√©marrons la stack.

```bash
 ‚úî Container csc8613-postgres-1  Running                                                                                                                                          0.0s 
 ‚úî Container csc8613-mlflow-1    Started                                                                                                                                          6.3s 
 ‚úî Container csc8613-feast-1     Started                                                                                                                                          6.1s 
 ‚úî Container csc8613-prefect-1   Started                                                                                                                                          6.3s 
 ‚úî Container csc8613-api-1       Started 
```

MLflow est bien lanc√© ainsi que postgres, feast, prefect et l'API.
Tous sont lanc√©s car sont d√©crit dans les services du Docker compose.

Nous pouvons v√©rifier que nous acc√©dons bien aux deux endpoints (API et MLflow).

![mlflow](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20104633.png)

![api](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20104725.png)

Nous checkons aussi que nous acc√©dons toujours √† l'endpoint `features/{user_id}`.

![api_user](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20105126.png)


## Exercice 2 : Cr√©er un script d‚Äôentra√Ænement + tracking MLflow (baseline RandomForest)

### Cr√©ation du script d'entrainement et ex√©cution
Dans cet exercice, nous allons compl√©ter un script train_baseline.py
qui :
1. construit un dataset d‚Äôentra√Ænement via des features d√©j√† disponibles,
2. entra√Æne un mod√®le baseline,
3. trace l‚Äôex√©cution dans MLfow (params, m√©triques, artefacts),
4. enregistre le mod√®le dans le Model Registry.

Lorsque nous enregistrons le mod√®le dans MLflow, il faut bien penser √† enregistrer toute la pipeline (preprocessing + mod√®le). Dans notre code on enregistre donc `pipe` et non `clf`.
En production, nous recevons les donn√©es brutes du FeatureStore, si on enregistrait seulement `clf`, les donn√©es brutes passeraient dans le mod√®le qui attends des donn√©es transform√©es.

Pour checker notre script, nous ex√©cutons le conteneur prefect sur month_000 (donc avec `TRAIN_AS_OF=2024-01-31`) avec :

```bash
docker compose exec -e TRAIN_AS_OF=2024-01-31 prefect python /opt/prefect/flows/train_baseline.py
```

### Interpr√©tation de l'ex√©cution

Apr√®s quelques warnings nous obtenons dans le terminal :

```bash
Model name: streamflow_churn, version 3
Created version '3' of model 'streamflow_churn'.
[OK] Trained baseline RF. AUC=0.6208 F1=0.0524 ACC=0.7535 (run_id=81d1fbefdbd4465c81f085bdf80f6d00)
2025/12/17 11:19:32 INFO mlflow.tracking._tracking_service.client: üèÉ View run rf_baseline_2024-01-31 at: http://mlflow:5000/#/experiments/1/runs/81d1fbefdbd4465c81f085bdf80f6d00.
2025/12/17 11:19:32 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow:5000/#/experiments/1.
```
Notre ex√©cution se termine bien en `[OK]` avec un `run_id=81d1fbefdbd4465c81f085bdf80f6d00`.
Dans cette log nous retrouvons aussi le score des 3 m√©triques `AUC=0.6208 F1=0.0524 ACC=0.7535`

C'est dans l'interface de MLflow que nous retrouvons nos colonnes cat√©gorielles et num√©riques :

![feature_schema](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20134656.png)

Une seule des features est num√©rique. Ce qui parrait coh√©rent car dans le dataset, toutes les autres features √©taient num√©riques ou prenaient 2 valeurs (bool√©en, ou 2 strings diff√©rents) sauf `net_service` qui prend au moins 3 valeurs **Fiber Optic**, **DSL**, **No**.


Ansi que les 3 m√©triques calcul√©es (AUC, F1, ACC) et le temps d'entrainement `train_time_sec=1.5825`

![metrics_time](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20134719.png)

J'ai fait le choix de rajouter un `mlflow.log_param` pour logger le nombre de lignes dans le dataset `training_rows=7043`


### Importance de `AS_OF` et `random_state`

On fixe `AS_OF`, pour pouvoir r√©cup√©rer les m√™me donn√©e d'entrainement √† chaque ex√©cution du script. Sans √ßa, le script r√©cupererait des donn√©es diff√©rentes (les plus r√©centes), ce qui rendrait impossible la reproducibilit√©.

Enfin `random_state` est fix√© pour garantir la reproducibilit√© des op√©rations al√©atoires. Ainsi d'une ex√©cution √† une autre, chaque op√©ration al√©atoire sera exactement la m√™me qu'√† l'ex√©cution pr√©cente. Donc l'entrainement, le split etc seront les m√™mes donc les m√©triques aussi.

Ces deux param√®tres sont tr√®s important en MLOps.

## Exercice 3 : Explorer l‚Äôinterface MLFlow et promouvoir un mod√®le

### Promotion de la version la plus r√©cente et fonctionnelle

Nous cherchons sur l'interface MLflow notre derni√®re exp√©rience en passant par `streamflow`, ensuite le dernier run en date.

Nous localisons le mod√®le `streamflow_churn` et cliquons pour le promouvoir vers le stage `Production`. Son num√©ro de version est `Version 3` (En effet, j'ai relanc√© 2 fois le mod√®le car pas tout √† fait correct)

Nous pouvons v√©rifier que c'est le seul en `Production` en checkant le `Registry Model`

![registry_model](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20141319.png)

### Importance de l'interface

La promotion via l'interface est pr√©f√©rable par rapport √† un d√©ploiement manuel car elle permet la **tra√ßabilit√©** avec chaques promotions + timestamp. Elle facilite le **rollback** puisqu'elle r√©pertorie toutes les versions existantes et qu'il suffit permuter les stages de 2 des versions pour revenir en arri√®re. Il est aussi possible de promouvoir en `Staging` avant de promouvoir en `Production` pour avoir un espace tampon et prevenir les bugs en production. Aussi, j'imagine que l'interface pr√©sente l'avantage de faciliter l'int√©gration CI/CD.


## Exercice 4 : √âtendre l‚ÄôAPI pour exposer /predict (serving minimal end-to-end)

L'objectif, ici, est de passer d‚Äôun endpoint ‚Äúfeatures‚Äù √† un vrai endpoint de pr√©diction en am√©liorant notre API pour qu'elle r√©cup√®re le mod√®le en production.

### Cr√©ation du endpoint `predict`

Nous modifions pour cela les `requirements.txt` de l'api et ajoutons `MLFLOW_TRACKING_URI`=http://mlflow:5000 dans .env.

Nous ajoutons ensuite dans `api/app.py` un endpoint `POST /predict` et permettons le chargement de `FeatureStore` ainsi que du mod√®le Mlflow en `Production` et nous finissons en red√©marrant l'API.

### Test de l'API et des pr√©dictions

Nous testons l'API en passant par Swagger UI
![predict](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20144811.png)

La requ√™te a bien fonctionn√© et la r√©ponse est la suivante :
```json
{
  "user_id": "7590-VHVEG",
  "prediction": 1,
  "features_used": {
    "plan_stream_tv": false,
    "monthly_fee": 29.850000381469727,
    "months_active": 1,
    "plan_stream_movies": false,
    "net_service": "DSL",
    "paperless_billing": true,
    "watch_hours_30d": 24.48365020751953,
    "skips_7d": 4,
    "avg_session_mins_7d": 29.14104461669922,
    "rebuffer_events_7d": 1,
    "unique_devices_30d": 3,
    "failed_payments_90d": 1,
    "ticket_avg_resolution_hrs_90d": 16,
    "support_tickets_90d": 0
  }
}
```
Le mod√®le pr√©dit un churn pour cet utilisateur.
Par ailleurs, le mod√®le dans l'api point vers `models:/streamflow_churn/Production` plut√¥t qu'un fichier local. Cela permet de ne pas d√©pendre de la version et donc de ne pas avoir √† modifier l'API en fonction. Le rollback ou la mise √† jour de version devient donc instantan√© (car pas de d√©pendance √† la version). En plus de tout cela, on √©vite les risques de **recopie de fichier ou de nom de fichiers compliqu√©s**

## Exercice 5 : Robustesse du serving : cas d‚Äô√©chec r√©alistes (sans monitoring)

### Tests `user_id` existant et inexistant

Nous exposons le cas d'un `user_id`existant
![predict_something](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20144811.png)

```json
{
  "user_id": "7590-VHVEG",
  "prediction": 1,
  "features_used": {
    "plan_stream_tv": false,
    "monthly_fee": 29.850000381469727,
    "months_active": 1,
    "plan_stream_movies": false,
    "net_service": "DSL",
    "paperless_billing": true,
    "watch_hours_30d": 24.48365020751953,
    "skips_7d": 4,
    "avg_session_mins_7d": 29.14104461669922,
    "rebuffer_events_7d": 1,
    "unique_devices_30d": 3,
    "failed_payments_90d": 1,
    "ticket_avg_resolution_hrs_90d": 16,
    "support_tickets_90d": 0
  }
}
```

Nous faisons √† pr√©sent le test avec un `user_id` non existant.
Voici, ce que nous obtenons :

![predict_nothing](./images_tp4/Capture%20d‚Äô√©cran%202025-12-17%20145916.png)

```json
{
  "error": "Missing features for user_id=7590",
  "missing_features": [
    "plan_stream_tv",
    "monthly_fee",
    "months_active",
    "plan_stream_movies",
    "net_service",
    "paperless_billing",
    "watch_hours_30d",
    "skips_7d",
    "avg_session_mins_7d",
    "rebuffer_events_7d",
    "unique_devices_30d",
    "failed_payments_90d",
    "ticket_avg_resolution_hrs_90d",
    "support_tickets_90d"
  ]
}
```
En effet, le mod√®le ne connait pas le user et donc ne peut rien pr√©dire.

### Robustesse du serving

**Deux causes principales d'√©chec**: 
1. **Entit√© absente** - Le `user_id` n'existe pas dans l'online store Feast ‚Üí toutes les features sont NULL
2. **Online store obsol√®te** - Les features ne sont pas √† jour (stale) ‚Üí valeurs manquantes

L'API d√©tecte ces deux cas via le check `X.isnull()` et retourne une erreur explicite avec `missing_features`. Sans cette v√©rification, le mod√®le ferait des pr√©dictions silencieuses sur des donn√©es incompl√®tes, ce qui est dangereux en production.


## Exercice 6 : R√©flexion de synth√®se (ing√©nierie MLOps)

### Avantages MLflow
MLFlow assure la **tra√ßabilit√© compl√®te** des entrainements : chaque run est enregistr√© avec un `run_id` unique, des **m√©triques** et **artefacts**, permettant d'identifier exactement quel mod√®le a produit quels r√©sultats. Le `Model Registry` organise les versions et les stages (None/Staging/Production), facilitant ainsi les **rollbacks** : pour revenir √† une version ant√©rieure, il suffit de changer son stage en `Production` sans toucher au code.

### D√©finition Stage Production
Le stage `Production` d√©finit quelle version du mod√®le l'API utiliser au d√©marrage via `models:/streamflow_churn/Production`. √Ä chaque requ√™te, l'API charge **automatiquement** la version marqu√©e `Production` sans modification de code. Cela permet les **rollbacks instantan√©s** : changer de version consiste √† relabelliser une autre version en `Production`, sans intervention sur l'API. C√¥t√© d√©ploiement, cela **pr√©vient les erreurs manuelles** (mauvais fichier, mauvaise version) et facilite la **CI/CD** en d√©couplant le versionning du code applicatif.

### Probl√®me restant contre la reproducibilit√©
M√™me avec le syst√®me complet (Feast + Prefect + PostgreSQL + MLflow + Docker), la reproductibilit√© peut casser si : les donn√©es PostgreSQL sont modifi√©es (pas de snapshot brut), les images Docker utilisent des tags flottants (python:3.10 peut changer silencieusement), ou l'online store Feast diverge de l'offline store (asynchrone).